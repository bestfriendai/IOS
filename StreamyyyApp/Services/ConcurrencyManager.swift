//
//  ConcurrencyManager.swift
//  StreamyyyApp
//
//  Advanced concurrency management service for optimized async/await patterns
//  Created by Claude Code on 2025-07-10
//

import Foundation
import Combine

// MARK: - Concurrency Manager

/// Advanced concurrency management service that provides optimized async/await patterns,
/// task management, and performance optimization for stream data operations
@MainActor
public class ConcurrencyManager: ObservableObject {
    
    // MARK: - Published Properties
    
    @Published public private(set) var activeTasks: [ManagedTask] = []
    @Published public private(set) var performanceMetrics: ConcurrencyMetrics = ConcurrencyMetrics()
    @Published public private(set) var resourceUtilization: ResourceUtilization = ResourceUtilization()
    
    // MARK: - Configuration
    
    public struct Configuration {
        public let maxConcurrentTasks: Int
        public let taskTimeoutDuration: TimeInterval
        public let enableTaskPrioritization: Bool
        public let enablePerformanceMonitoring: Bool
        public let enableAdaptiveConcurrency: Bool
        public let resourceThrottlingThreshold: Double
        
        public init(
            maxConcurrentTasks: Int = 10,
            taskTimeoutDuration: TimeInterval = 30.0,
            enableTaskPrioritization: Bool = true,
            enablePerformanceMonitoring: Bool = true,
            enableAdaptiveConcurrency: Bool = true,
            resourceThrottlingThreshold: Double = 0.8
        ) {
            self.maxConcurrentTasks = maxConcurrentTasks
            self.taskTimeoutDuration = taskTimeoutDuration
            self.enableTaskPrioritization = enableTaskPrioritization
            self.enablePerformanceMonitoring = enablePerformanceMonitoring
            self.enableAdaptiveConcurrency = enableAdaptiveConcurrency
            self.resourceThrottlingThreshold = resourceThrottlingThreshold
        }
    }
    
    private let configuration: Configuration
    
    // MARK: - Task Management
    
    private let taskQueue: TaskQueue
    private let resourceMonitor: ResourceMonitor
    private let performanceAnalyzer: PerformanceAnalyzer
    private var taskGroups: [String: TaskGroup<Any, Error>] = [:]
    
    // MARK: - Synchronization
    
    private let taskLock = NSLock()
    private let metricsLock = NSLock()
    
    // MARK: - Initialization
    
    public init(configuration: Configuration = Configuration()) {
        self.configuration = configuration
        self.taskQueue = TaskQueue(maxConcurrency: configuration.maxConcurrentTasks)
        self.resourceMonitor = ResourceMonitor()
        self.performanceAnalyzer = PerformanceAnalyzer()
        
        setupMonitoring()
    }
    
    // MARK: - Public Task Management Methods
    
    /// Execute a single async operation with priority and timeout management
    public func execute<T>(\n        _ operation: @escaping () async throws -> T,\n        priority: TaskPriority = .medium,\n        timeout: TimeInterval? = nil,\n        context: TaskContext\n    ) async throws -> T {\n        \n        let task = ManagedTask(\n            id: UUID(),\n            name: context.name,\n            priority: priority,\n            timeout: timeout ?? configuration.taskTimeoutDuration,\n            context: context,\n            startTime: Date()\n        )\n        \n        await addTask(task)\n        \n        defer {\n            Task {\n                await self.removeTask(task.id)\n            }\n        }\n        \n        return try await taskQueue.execute(\n            operation,\n            priority: priority,\n            timeout: task.timeout\n        )\n    }\n    \n    /// Execute multiple operations concurrently with intelligent batching\n    public func executeConcurrently<T>(\n        _ operations: [() async throws -> T],\n        maxConcurrency: Int? = nil,\n        priority: TaskPriority = .medium,\n        context: TaskContext\n    ) async throws -> [T] {\n        \n        let concurrencyLimit = min(\n            maxConcurrency ?? configuration.maxConcurrentTasks,\n            operations.count\n        )\n        \n        return try await withThrowingTaskGroup(of: (Int, T).self) { group in\n            var index = 0\n            var results: [T?] = Array(repeating: nil, count: operations.count)\n            \n            // Add initial batch of tasks\n            for _ in 0..<min(concurrencyLimit, operations.count) {\n                let currentIndex = index\n                group.addTask(priority: priority) {\n                    let result = try await operations[currentIndex]()\n                    return (currentIndex, result)\n                }\n                index += 1\n            }\n            \n            // Process results and add remaining tasks\n            for try await (resultIndex, result) in group {\n                results[resultIndex] = result\n                \n                // Add next task if available\n                if index < operations.count {\n                    let currentIndex = index\n                    group.addTask(priority: priority) {\n                        let result = try await operations[currentIndex]()\n                        return (currentIndex, result)\n                    }\n                    index += 1\n                }\n            }\n            \n            return results.compactMap { $0 }\n        }\n    }\n    \n    /// Execute operations with automatic retry and error handling\n    public func executeWithRetry<T>(\n        _ operation: @escaping () async throws -> T,\n        maxRetries: Int = 3,\n        retryDelay: TimeInterval = 1.0,\n        priority: TaskPriority = .medium,\n        context: TaskContext\n    ) async throws -> T {\n        \n        var lastError: Error?\n        \n        for attempt in 1...(maxRetries + 1) {\n            do {\n                return try await execute(\n                    operation,\n                    priority: priority,\n                    context: context.withAttempt(attempt)\n                )\n            } catch {\n                lastError = error\n                \n                if attempt <= maxRetries {\n                    // Calculate exponential backoff delay\n                    let delay = retryDelay * pow(2.0, Double(attempt - 1))\n                    try await Task.sleep(nanoseconds: UInt64(delay * 1_000_000_000))\n                }\n            }\n        }\n        \n        throw lastError ?? ConcurrencyError.maxRetriesExceeded\n    }\n    \n    /// Execute operations in a streaming fashion with backpressure handling\n    public func executeStream<T>(\n        _ operations: AsyncSequence<() async throws -> T>,\n        bufferSize: Int = 5,\n        priority: TaskPriority = .medium,\n        context: TaskContext\n    ) -> AsyncThrowingStream<T, Error> {\n        \n        return AsyncThrowingStream { continuation in\n            Task {\n                do {\n                    var buffer: [Task<T, Error>] = []\n                    \n                    for try await operation in operations {\n                        // Maintain buffer size\n                        if buffer.count >= bufferSize {\n                            let completedTask = buffer.removeFirst()\n                            let result = try await completedTask.value\n                            continuation.yield(result)\n                        }\n                        \n                        // Add new task to buffer\n                        let task = Task(priority: priority) {\n                            try await operation()\n                        }\n                        buffer.append(task)\n                    }\n                    \n                    // Process remaining buffered tasks\n                    for task in buffer {\n                        let result = try await task.value\n                        continuation.yield(result)\n                    }\n                    \n                    continuation.finish()\n                } catch {\n                    continuation.finish(throwing: error)\n                }\n            }\n        }\n    }\n    \n    /// Execute operations with resource-aware throttling\n    public func executeThrottled<T>(\n        _ operation: @escaping () async throws -> T,\n        priority: TaskPriority = .medium,\n        context: TaskContext\n    ) async throws -> T {\n        \n        // Check resource utilization\n        if configuration.enableAdaptiveConcurrency {\n            await waitForResources()\n        }\n        \n        return try await execute(operation, priority: priority, context: context)\n    }\n    \n    /// Cancel a specific task\n    public func cancelTask(id: UUID) async {\n        await removeTask(id)\n        taskQueue.cancelTask(id: id)\n    }\n    \n    /// Cancel all tasks in a specific context\n    public func cancelTasks(in context: String) async {\n        let tasksToCancel = activeTasks.filter { $0.context.category == context }\n        \n        for task in tasksToCancel {\n            await cancelTask(id: task.id)\n        }\n    }\n    \n    /// Cancel all active tasks\n    public func cancelAllTasks() async {\n        let taskIds = activeTasks.map { $0.id }\n        \n        for id in taskIds {\n            await cancelTask(id: id)\n        }\n    }\n    \n    // MARK: - Performance Monitoring\n    \n    /// Get current performance metrics\n    public func getPerformanceMetrics() -> ConcurrencyMetrics {\n        return performanceMetrics\n    }\n    \n    /// Get resource utilization information\n    public func getResourceUtilization() -> ResourceUtilization {\n        return resourceUtilization\n    }\n    \n    /// Get detailed task information\n    public func getTaskDetails() -> [ManagedTask] {\n        return activeTasks\n    }\n    \n    // MARK: - Private Methods\n    \n    private func addTask(_ task: ManagedTask) async {\n        taskLock.lock()\n        defer { taskLock.unlock() }\n        \n        activeTasks.append(task)\n        updateMetrics()\n    }\n    \n    private func removeTask(_ id: UUID) async {\n        taskLock.lock()\n        defer { taskLock.unlock() }\n        \n        if let index = activeTasks.firstIndex(where: { $0.id == id }) {\n            let task = activeTasks.remove(at: index)\n            recordTaskCompletion(task)\n        }\n        \n        updateMetrics()\n    }\n    \n    private func recordTaskCompletion(_ task: ManagedTask) {\n        let duration = Date().timeIntervalSince(task.startTime)\n        performanceAnalyzer.recordTaskCompletion(\n            context: task.context,\n            duration: duration,\n            priority: task.priority\n        )\n    }\n    \n    private func updateMetrics() {\n        metricsLock.lock()\n        defer { metricsLock.unlock() }\n        \n        let now = Date()\n        let activeCount = activeTasks.count\n        let averageDuration = performanceAnalyzer.getAverageTaskDuration()\n        \n        performanceMetrics = ConcurrencyMetrics(\n            activeTasks: activeCount,\n            averageTaskDuration: averageDuration,\n            taskThroughput: calculateThroughput(),\n            resourceEfficiency: calculateResourceEfficiency(),\n            lastUpdated: now\n        )\n    }\n    \n    private func calculateThroughput() -> Double {\n        return performanceAnalyzer.calculateThroughput()\n    }\n    \n    private func calculateResourceEfficiency() -> Double {\n        let currentUtilization = resourceMonitor.getCurrentUtilization()\n        let targetUtilization = configuration.resourceThrottlingThreshold\n        \n        if currentUtilization <= targetUtilization {\n            return 1.0\n        } else {\n            return targetUtilization / currentUtilization\n        }\n    }\n    \n    private func waitForResources() async {\n        while resourceMonitor.getCurrentUtilization() > configuration.resourceThrottlingThreshold {\n            try? await Task.sleep(nanoseconds: 100_000_000) // 100ms\n        }\n    }\n    \n    private func setupMonitoring() {\n        if configuration.enablePerformanceMonitoring {\n            Timer.scheduledTimer(withTimeInterval: 5.0, repeats: true) { _ in\n                Task {\n                    await self.updateResourceUtilization()\n                    await self.performMaintenanceTasks()\n                }\n            }\n        }\n    }\n    \n    private func updateResourceUtilization() async {\n        resourceUtilization = resourceMonitor.getResourceUtilization()\n    }\n    \n    private func performMaintenanceTasks() async {\n        // Clean up completed tasks\n        let now = Date()\n        let expiredTasks = activeTasks.filter {\n            now.timeIntervalSince($0.startTime) > $0.timeout\n        }\n        \n        for task in expiredTasks {\n            await cancelTask(id: task.id)\n        }\n        \n        // Update performance analytics\n        performanceAnalyzer.performMaintenance()\n    }\n}\n\n// MARK: - Supporting Types\n\n/// Task context information\npublic struct TaskContext {\n    public let name: String\n    public let category: String\n    public let metadata: [String: String]\n    public let attempt: Int\n    \n    public init(\n        name: String,\n        category: String,\n        metadata: [String: String] = [:],\n        attempt: Int = 1\n    ) {\n        self.name = name\n        self.category = category\n        self.metadata = metadata\n        self.attempt = attempt\n    }\n    \n    public func withAttempt(_ attempt: Int) -> TaskContext {\n        return TaskContext(\n            name: name,\n            category: category,\n            metadata: metadata,\n            attempt: attempt\n        )\n    }\n}\n\n/// Task priority levels\npublic enum TaskPriority: Int, CaseIterable {\n    case low = 1\n    case medium = 2\n    case high = 3\n    case critical = 4\n    \n    public var displayName: String {\n        switch self {\n        case .low: return "Low"\n        case .medium: return "Medium"\n        case .high: return "High"\n        case .critical: return "Critical"\n        }\n    }\n    \n    public var systemPriority: _Concurrency.TaskPriority {\n        switch self {\n        case .low: return .low\n        case .medium: return .medium\n        case .high: return .high\n        case .critical: return .high // Map critical to system high\n        }\n    }\n}\n\n/// Managed task information\npublic struct ManagedTask: Identifiable {\n    public let id: UUID\n    public let name: String\n    public let priority: TaskPriority\n    public let timeout: TimeInterval\n    public let context: TaskContext\n    public let startTime: Date\n    \n    public var duration: TimeInterval {\n        return Date().timeIntervalSince(startTime)\n    }\n    \n    public var isExpired: Bool {\n        return duration > timeout\n    }\n}\n\n/// Concurrency performance metrics\npublic struct ConcurrencyMetrics {\n    public let activeTasks: Int\n    public let averageTaskDuration: TimeInterval\n    public let taskThroughput: Double // tasks per second\n    public let resourceEfficiency: Double // 0.0 to 1.0\n    public let lastUpdated: Date\n    \n    public init(\n        activeTasks: Int = 0,\n        averageTaskDuration: TimeInterval = 0,\n        taskThroughput: Double = 0,\n        resourceEfficiency: Double = 1.0,\n        lastUpdated: Date = Date()\n    ) {\n        self.activeTasks = activeTasks\n        self.averageTaskDuration = averageTaskDuration\n        self.taskThroughput = taskThroughput\n        self.resourceEfficiency = resourceEfficiency\n        self.lastUpdated = lastUpdated\n    }\n}\n\n/// Resource utilization information\npublic struct ResourceUtilization {\n    public let cpuUsage: Double\n    public let memoryUsage: Double\n    public let networkUsage: Double\n    public let diskUsage: Double\n    public let timestamp: Date\n    \n    public init(\n        cpuUsage: Double = 0,\n        memoryUsage: Double = 0,\n        networkUsage: Double = 0,\n        diskUsage: Double = 0,\n        timestamp: Date = Date()\n    ) {\n        self.cpuUsage = cpuUsage\n        self.memoryUsage = memoryUsage\n        self.networkUsage = networkUsage\n        self.diskUsage = diskUsage\n        self.timestamp = timestamp\n    }\n    \n    public var overallUtilization: Double {\n        return (cpuUsage + memoryUsage + networkUsage + diskUsage) / 4.0\n    }\n}\n\n/// Concurrency errors\npublic enum ConcurrencyError: Error, LocalizedError {\n    case taskTimeout\n    case maxConcurrencyExceeded\n    case maxRetriesExceeded\n    case resourceExhausted\n    case taskCancelled\n    \n    public var errorDescription: String? {\n        switch self {\n        case .taskTimeout:\n            return "Task execution timeout"\n        case .maxConcurrencyExceeded:\n            return "Maximum concurrency limit exceeded"\n        case .maxRetriesExceeded:\n            return "Maximum retry attempts exceeded"\n        case .resourceExhausted:\n            return "System resources exhausted"\n        case .taskCancelled:\n            return "Task was cancelled"\n        }\n    }\n}\n\n// MARK: - Helper Classes\n\n/// Task queue with priority and concurrency management\npublic class TaskQueue {\n    private let maxConcurrency: Int\n    private var activeTasks: [UUID: Task<Any, Error>] = [:]\n    private let semaphore: AsyncSemaphore\n    \n    public init(maxConcurrency: Int) {\n        self.maxConcurrency = maxConcurrency\n        self.semaphore = AsyncSemaphore(value: maxConcurrency)\n    }\n    \n    public func execute<T>(\n        _ operation: @escaping () async throws -> T,\n        priority: TaskPriority,\n        timeout: TimeInterval\n    ) async throws -> T {\n        \n        await semaphore.wait()\n        \n        defer {\n            semaphore.signal()\n        }\n        \n        return try await withThrowingTaskGroup(of: T.self) { group in\n            group.addTask(priority: priority.systemPriority) {\n                try await operation()\n            }\n            \n            // Add timeout task\n            group.addTask(priority: .low) {\n                try await Task.sleep(nanoseconds: UInt64(timeout * 1_000_000_000))\n                throw ConcurrencyError.taskTimeout\n            }\n            \n            // Return first completed result\n            let result = try await group.next()!\n            group.cancelAll()\n            return result\n        }\n    }\n    \n    public func cancelTask(id: UUID) {\n        activeTasks[id]?.cancel()\n        activeTasks.removeValue(forKey: id)\n    }\n}\n\n/// Async semaphore for concurrency control\npublic actor AsyncSemaphore {\n    private var value: Int\n    private var waiters: [CheckedContinuation<Void, Never>] = []\n    \n    public init(value: Int) {\n        self.value = value\n    }\n    \n    public func wait() async {\n        if value > 0 {\n            value -= 1\n            return\n        }\n        \n        await withCheckedContinuation { continuation in\n            waiters.append(continuation)\n        }\n    }\n    \n    public func signal() {\n        if waiters.isEmpty {\n            value += 1\n        } else {\n            let waiter = waiters.removeFirst()\n            waiter.resume()\n        }\n    }\n}\n\n/// Resource monitoring service\npublic class ResourceMonitor {\n    private var lastMeasurement = Date()\n    private var cachedUtilization = ResourceUtilization()\n    \n    public func getCurrentUtilization() -> Double {\n        return getResourceUtilization().overallUtilization\n    }\n    \n    public func getResourceUtilization() -> ResourceUtilization {\n        let now = Date()\n        \n        // Update cached values every second to avoid excessive measurements\n        if now.timeIntervalSince(lastMeasurement) > 1.0 {\n            cachedUtilization = measureResourceUtilization()\n            lastMeasurement = now\n        }\n        \n        return cachedUtilization\n    }\n    \n    private func measureResourceUtilization() -> ResourceUtilization {\n        // In a real implementation, this would measure actual system resources\n        // For now, we'll return simulated values\n        \n        let cpuUsage = Double.random(in: 0.1...0.8)\n        let memoryUsage = Double.random(in: 0.2...0.7)\n        let networkUsage = Double.random(in: 0.0...0.5)\n        let diskUsage = Double.random(in: 0.1...0.4)\n        \n        return ResourceUtilization(\n            cpuUsage: cpuUsage,\n            memoryUsage: memoryUsage,\n            networkUsage: networkUsage,\n            diskUsage: diskUsage,\n            timestamp: Date()\n        )\n    }\n}\n\n/// Performance analysis service\npublic class PerformanceAnalyzer {\n    private var taskCompletions: [TaskCompletionRecord] = []\n    private let maxRecords = 1000\n    \n    public func recordTaskCompletion(\n        context: TaskContext,\n        duration: TimeInterval,\n        priority: TaskPriority\n    ) {\n        let record = TaskCompletionRecord(\n            context: context,\n            duration: duration,\n            priority: priority,\n            timestamp: Date()\n        )\n        \n        taskCompletions.append(record)\n        \n        // Keep only recent records\n        if taskCompletions.count > maxRecords {\n            taskCompletions.removeFirst(taskCompletions.count - maxRecords)\n        }\n    }\n    \n    public func getAverageTaskDuration() -> TimeInterval {\n        guard !taskCompletions.isEmpty else { return 0 }\n        \n        let totalDuration = taskCompletions.reduce(0) { $0 + $1.duration }\n        return totalDuration / Double(taskCompletions.count)\n    }\n    \n    public func calculateThroughput() -> Double {\n        let now = Date()\n        let recentCompletions = taskCompletions.filter {\n            now.timeIntervalSince($0.timestamp) < 60 // Last minute\n        }\n        \n        return Double(recentCompletions.count) / 60.0 // tasks per second\n    }\n    \n    public func performMaintenance() {\n        let cutoffTime = Date().addingTimeInterval(-3600) // 1 hour ago\n        taskCompletions.removeAll { $0.timestamp < cutoffTime }\n    }\n    \n    private struct TaskCompletionRecord {\n        let context: TaskContext\n        let duration: TimeInterval\n        let priority: TaskPriority\n        let timestamp: Date\n    }\n}"